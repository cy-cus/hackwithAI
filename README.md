# ğŸ¦… HackwithAI - LLM-Powered Security Reconnaissance

> **AI-driven reconnaissance and security analysis tool with a Matrix-inspired interface**

A cutting-edge reconnaissance platform that combines traditional security tools with Large Language Model (LLM) analysis to discover and analyze attack surfaces intelligently.

---

## ğŸ¯ Features

### Core Capabilities
- **ğŸ” Subdomain Discovery** â€“ Find hidden subdomains using subfinder
- **ğŸŒ URL Collection** â€“ Gather URLs from waybackurls, katana, and httpx
- **ğŸ“¡ Endpoint Extraction** â€“ Extract API paths from URLs and JavaScript
- **ğŸ“„ JavaScript Analysis** â€“ Browser-based JS discovery with Playwright (captures dynamic scripts)
- **ğŸ§­ Domain-Scoped Crawling** â€“ Strict filtering keeps Wayback results scoped to the exact domain while JSleuth explores only the target domain and its subdomains
- **ğŸ”’ Secret Detection** â€“ Find API keys, tokens, and credentials
- **ğŸ¤– AI-Powered Analysis** â€“ Intelligent security findings using Ollama with triple-tier refusal recovery
- **ğŸ¯ Targeted Scanning** â€“ Deep-dive analysis on selected findings, secrets, endpoints, or JS files with 20â€‘minute LLM context windows
- **ğŸ—‚ï¸ Output Browser Tools** â€“ Let the chat LLM explore scan folders (list_dir/read_file/search_content) for precise answers
- **ğŸ’¬ AI Chat Interface** â€“ Ask questions about scan results; the agent automatically reinforces authorized-testing context and uses file browsing when needed

### User Experience
- **Matrix-Style UI** - Pure hacker aesthetic (neon green #00ff41 + pink #ff0080)
- **Full-Screen Scanner** - Animated progress overlay with Matrix rain effect
- **Real-Time Updates** - WebSocket-powered live scanning progress
- **Search & Filter** - Instant filtering on all results
- **Organized Output** - Clean file structure with JSON exports

---

## ğŸš€ Quick Start

### Prerequisites
```bash
# Python 3.11+
python3.11 --version

# Ollama (for LLM analysis)
curl https://ollama.ai/install.sh | sh
ollama pull llama3.1:8b

# Security Tools
# Install subfinder, httpx, katana, waybackurls, etc.
```

### Installation

```bash
# Clone & Navigate
cd ~/Desktop/llm

# Create Python 3.11 virtual environment
python3.11 -m venv venv
source venv/bin/activate

# Install dependencies
pip install --upgrade pip
pip install -r requirements.txt

# Install Playwright browsers (required for JS discovery)
playwright install chromium

# Start Ollama (in separate terminal)
ollama serve

# Run HackwithAI (factory flag silences ASGI warning)
uvicorn reconai.web.app:create_app --factory --reload --host 0.0.0.0 --port 8000
```

### Access
Open **http://localhost:8000** in your browser

> **Tip:** If Playwright complains about missing browsers, re-run `playwright install chromium`. This only needs to be done once per environment.

---

## ğŸ§­ Domain & Scope Controls

HackwithAI strictly respects user-provided scopes:

1. **Waybackurls Filtering** â€“ Only keeps URLs where the host matches `domain` or `www.domain`. Historic data from unrelated subdomains is automatically discarded.
2. **JSleuth Allowed Domains** â€“ The Playwright crawler receives the exact domain, plus any discovered subdomains, as its allowed set. It follows internal links but never leaves that scope.
3. **JS URL Deduping & Size Modes** â€“ All `.js` URLs from Katana + Wayback + JSleuth are deduplicated, then clipped by `js_size` (small=100, medium=1000, large=all). Inline scripts are analyzed the same as external files.
4. **Chat Context Guardrails** â€“ The chat endpoint automatically reinforces authorized-testing context and retries any model refusal so that domain findings can be discussed confidently.

---

## ğŸ“– Usage

### 1. Basic Scan
```
1. Enter target domain: example.com
2. Select LLM model: Llama 3.1 8B
3. Choose JS analysis size: Medium (1000 files)
4. Click "ğŸš€ Start Scan"
5. Watch the Matrix-style scanner overlay!
```

### 2. Scan Modes

#### **ğŸŒ Single Domain**
Full reconnaissance on one target:
- Subdomain discovery
- URL collection from multiple sources
- JavaScript file analysis
- Secret detection
- LLM security analysis

#### **ğŸŒ Multiple Domains**
Bulk scanning:
- Enter multiple domains (one per line)
- Runs reconnaissance on each
- Aggregated results

#### **ğŸ“„ JS Only**
Direct JavaScript analysis:
- Skip subdomain discovery
- Analyze specific JS file URLs
- Extract endpoints & secrets
- Fast & focused

### 3. Targeted Scanning ğŸ¯

**What it does:**
When you select specific findings, secrets, endpoints, or JS files and click "ğŸ¤– Scan Selected with AI", the system:

1. **Identifies Relevant Files**
   - **Findings**: Scans all JS files + injects affected endpoints/parameters/evidence
   - **Secrets**: Finds the JS file where the secret was discovered
   - **Endpoints**: Collects ALL JavaScript files (endpoints come from multiple sources)
   - **JS Files**: Uses exactly the JS files you selected

2. **Fetches Source Code**
   - Downloads complete JS file content
   - Maintains source tracking for context

3. **Prepares LLM Context**
   - Creates detailed prompt with:
     * Selected items (endpoints/secrets)
     * Complete source code from relevant JS files
     * Request for security analysis

4. **LLM Analysis**
   - Ollama processes the context (up to 20 minutes timeout)
   - Analyzes code for:
     * Security vulnerabilities
     * Authentication issues
     * Authorization flaws
     * Data exposure risks
     * Common attack vectors

5. **Displays Results**
   - Shows comprehensive AI-generated security report
   - Includes affected items, severity, and recommendations

**Example Use Cases:**
- Analyze authentication endpoints for security flaws
- Investigate suspicious API keys found in JS
- Deep-dive into payment processing endpoints
- Examine admin panel access controls

> **Inline Scripts Included:** JSleuth saves inline scripts (e.g., `inline#23`) alongside external `.js` files so that targeted scans consider DOM-embedded logic as well.

### 4. AI Chat Interface ğŸ’¬

Ask questions about your scan results:
```
"Show me all authentication endpoints"
"Which secrets are critical?"
"Summarize the attack surface"
"What are the highest risk findings?"
```

The LLM has access to:
- All discovered URLs and endpoints
- Extracted secrets (with file + line references)
- JavaScript analysis results
- Security findings and evidence

If the model ever responds with a refusal, HackwithAI automatically re-prompts it (three escalating prompts) and, when needed, uses the output browser tools described below.

### 5. AI Output Browser Tools ğŸ“‚

When the question requires raw evidence, the chat agent can request file data instead of dumping everything into the prompt. Available tools:

| Tool | Purpose | Example |
| --- | --- | --- |
| `LIST_DIR` | Enumerate folders/files inside the current scan output | `TOOL_REQUEST: {"tool":"list_dir","path":"output/example.com_20251118_043942/js_files"}` |
| `READ_FILE` | Read a full file or slice (JSON auto-parses) | `TOOL_REQUEST: {"tool":"read_file","path":".../secrets.json","offset":0,"limit":200}` |
| `SEARCH_CONTENT` | Find strings across files/directories | `TOOL_REQUEST: {"tool":"search_content","path":".../js_files","query":"admin"}` |
| `GET_SCAN_SUMMARY` | Summarize high-level stats for the scan | `TOOL_REQUEST: {"tool":"get_scan_summary"}` |

**Usage:** The LLM prints the tool request as JSON prefixed with `TOOL_REQUEST:`. The backend executes it, appends the result as `TOOL_RESULT`, and the LLM either asks for more data or replies with `FINAL_ANSWER:`.

---

## ğŸ—ï¸ Architecture

### Project Structure
```
/home/cyky/Desktop/llm/
â”œâ”€â”€ reconai/
â”‚   â”œâ”€â”€ models.py           # Pydantic data models
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â””â”€â”€ ollama.py       # Ollama LLM backend
â”‚   â”œâ”€â”€ recon/
â”‚   â”‚   â”œâ”€â”€ subfinder.py    # Subdomain discovery
â”‚   â”‚   â”œâ”€â”€ waybackurls.py  # Historical URL collection
â”‚   â”‚   â”œâ”€â”€ katana.py       # Web crawler
â”‚   â”‚   â”œâ”€â”€ httpx.py        # HTTP probing
â”‚   â”‚   â””â”€â”€ jsanalyzer.py   # JavaScript analysis
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ output_manager.py      # File organization
â”‚   â”‚   â”œâ”€â”€ endpoint_extractor.py  # API path extraction
â”‚   â”‚   â””â”€â”€ json_encoder.py        # Datetime serialization
â”‚   â”œâ”€â”€ analyzer.py         # LLM security analysis
â”‚   â””â”€â”€ web/
â”‚       â”œâ”€â”€ app.py          # FastAPI application
â”‚       â””â”€â”€ templates/
â”‚           â””â”€â”€ index.html  # Matrix-style UI
â”œâ”€â”€ output/                 # Scan results
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md              # This file
```

### Data Flow

1. **Reconnaissance Phase**
   ```
   Target â†’ Subfinder â†’ Subdomains
         â†’ Waybackurls â†’ URLs
         â†’ Katana â†’ URLs  
         â†’ Httpx â†’ URLs
         â†’ JSLeuth/JSFetcher â†’ JS Files
   ```

2. **Analysis Phase**
   ```
   JS Files â†’ JSAnalyzer â†’ Endpoints, Secrets, Links
   URLs â†’ Endpoint Extractor â†’ API Paths
   All Data â†’ LLM â†’ Security Findings
   ```

3. **Storage**
   ```
   Results â†’ OutputManager â†’ Organized Folders
                           â†’ JSON Files
                           â†’ Summary Reports
   ```

### WebSocket Real-Time Updates
```
Scan Start â†’ WebSocket Connection â†’ Progress Updates
                                  â†’ Status Messages
                                  â†’ Live Stats
                                  â†’ Scan Complete
```

---

## ğŸ¨ UI Theme: Hacker Matrix Style

### Color Palette
```css
Matrix Green:  #00ff41  /* Primary UI color */
Neon Pink:     #ff0080  /* CTAs & accents */
Pure Black:    #000000  /* Background */
Dark Gray:     #0a0e0f  /* Secondary bg */
```

### Key Visual Elements
- âœ… Matrix rain effect (falling Japanese/binary characters)
- âœ… Animated scan line with pink pulse
- âœ… Glowing green text with pulsing shadow
- âœ… Full-screen scanner overlay during scans
- âœ… Real-time stats counter
- âœ… Timeline with glowing step dots
- âœ… Zero blue/cyan colors anywhere

---

## ğŸ“Š Output Structure

After each scan, results are saved in organized folders:

```
output/
â””â”€â”€ example.com_20251116_183240/
    â”œâ”€â”€ subdomains/
    â”‚   â”œâ”€â”€ subdomains.txt
    â”‚   â””â”€â”€ subdomains.json
    â”œâ”€â”€ endpoints/
    â”‚   â”œâ”€â”€ endpoints.txt
    â”‚   â””â”€â”€ endpoints.json
    â”œâ”€â”€ parameters/
    â”‚   â”œâ”€â”€ parameters.json
    â”‚   â””â”€â”€ suspicious_parameters.txt
    â”œâ”€â”€ js_files/
    â”‚   â”œâ”€â”€ js_urls.txt
    â”‚   â”œâ”€â”€ js_files.json
    â”‚   â””â”€â”€ raw/
    â”‚       â”œâ”€â”€ script1.js
    â”‚       â”œâ”€â”€ script1.meta.json
    â”‚       â””â”€â”€ ...
    â”œâ”€â”€ secrets/
    â”‚   â”œâ”€â”€ secrets.json
    â”‚   â””â”€â”€ CRITICAL_SECRETS.txt
    â”œâ”€â”€ findings/
    â”‚   â”œâ”€â”€ findings.json
    â”‚   â””â”€â”€ findings_summary.txt
    â”œâ”€â”€ raw/
    â”‚   â””â”€â”€ attack_surface.json
    â”œâ”€â”€ reports/
    â”‚   â””â”€â”€ summary.txt
    â””â”€â”€ scan_state.json
```

---

## ğŸ”§ Configuration

### Environment Variables
Create a `.env` file:
```ini
# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
DEFAULT_MODEL=llama3.1:8b

# Application Settings
DEBUG=true
LOG_LEVEL=INFO
PORT=8000
```

### LLM Timeout Settings
The default timeout is now **1200 seconds (20 minutes)** to handle large targeted scans.

Edit `reconai/llm/ollama.py` to adjust:
```python
timeout: int = 1200  # seconds
```

---

## ğŸ› Troubleshooting

### "Playwright executable doesn't exist"
```
Looks like Playwright was just installed or updated.
Please run: playwright install chromium
```
**Solution:** Activate your virtualenv and run `playwright install chromium` once. The JS discovery engine will then launch Chromium headlessly.

### "Ollama request timed out"
**Solution:**
- Increase timeout in `reconai/llm/ollama.py` (already set to 20 min)
- Use a smaller/faster model (e.g., `deepseek-coder:1.3b`)
- Reduce the number of selected items for targeted scanning
- Ensure Ollama is running: `ollama serve`

### "Failed to save subdomains: datetime serialization"
**Solution:**
- Already fixed! All Pydantic models now have `ConfigDict` with datetime serialization
- Models automatically convert datetime to ISO format

### Port already in use
```bash
# Find and kill process
sudo lsof -i :8000
kill -9 <PID>

# Or use a different port
uvicorn reconai.web.app:create_app --port 8080
```

### Ollama not responding
```bash
# Check if Ollama is running
curl http://localhost:11434/api/tags

# Start Ollama
ollama serve

# Verify model is downloaded
ollama list
ollama pull llama3.1:8b
```

---

## ğŸ” How Targeted Scanning Works

### Backend Process (`/api/scan/targeted`)

When you click "ğŸ¤– Scan Selected with AI":

1. **Request Received**
   ```python
   {
       "scan_id": "example.com_20251116_183240",
       "target_type": "endpoint",  # or "secret"
       "target_items": ["/api/users", "/api/auth/login"],
       "focus": "security",
       "model": "llama3.1:8b"
   }
   ```

2. **Load Scan Results**
   - Retrieves stored scan data from `active_scans` or file system
   - Validates scan exists and has results

3. **Identify Source Files**
   
   **For Secrets:**
   ```python
   # Find the JS file where each secret was found
   for secret in selected_secrets:
       js_file_url = endpoint_sources.get(secret)
       js_files_to_scan.add(js_file_url)
   ```
   
   **For Endpoints:**
   ```python
   # Scan ALL JS files (endpoints come from multiple sources)
   for js_file in all_discovered_js_files:
       js_files_to_scan.add(js_file.url)
   ```

4. **Fetch JS Content**
   ```python
   async def fetch_js_content(url):
       response = await httpx.get(url, timeout=30)
       return {
           'url': url,
           'content': response.text,
           'size': len(response.text)
       }
   ```

5. **Build LLM Prompt**
   ```python
   prompt = f"""
   Analyze these {target_type}s for security issues:
   
   Selected Items:
   {json.dumps(selected_items_info, indent=2)}
   
   Source Code from {len(js_contents)} JavaScript files:
   
   File: {js_url}
   ---
   {js_content}
   ---
   
   Provide detailed security analysis...
   """
   ```

6. **LLM Analysis**
   ```python
   analysis = await llm.generate(
       prompt=prompt,
       temperature=0.3,
       max_tokens=4096,
       timeout=1200  # 20 minutes
   )
   ```

7. **Return Results**
   ```json
   {
       "analysis": "Security Analysis:\n\n1. Authentication...",
       "items_analyzed": 2,
       "js_files_scanned": 18,
       "model_used": "llama3.1:8b"
   }
   ```

### Frontend Display
- Shows loading modal while LLM analyzes
- Displays comprehensive security report
- Allows copying/exporting results

---

## ğŸ“ Recent Fixes & Improvements

### âœ… Datetime Serialization Fixed
- Added `ConfigDict` to all Pydantic models
- All datetime fields now serialize to ISO format
- No more "Object of type datetime is not JSON serializable" errors
- Fixed `model_name` namespace warning

### âœ… Timeout Issues Resolved
- Increased default LLM timeout from 300s â†’ 1200s (20 minutes)
- Per-call timeout parameter support
- Better error messages with actual timeout values

### âœ… Complete UI Overhaul
- Removed ALL blue/cyan colors
- Pure Matrix hacker theme (green + pink)
- Full-screen animated scanner overlay
- Matrix rain background effect
- Glowing text animations
- Real-time stats counter
- Timeline with animated steps

### âœ… Targeted Scanning Improved
- Findings, Secrets, Endpoints, and JS Files tabs all support "Scan Selected with AI"
- Endpoints now scan ALL JS files for complete context
- Secrets scan specific source files
- Findings include affected endpoints, parameters, and evidence in AI prompt
- JS tab allows direct selection of scripts to analyze
- Better error handling + longer timeout support

### âœ… AI Output Browser
- Chat agent can now browse `output/<scan_id>/...` safely
- Supports listing folders, reading files, and grepping for strings
- Enables precise answers referencing exact files/lines without bloated prompts

### âœ… Search Functionality
- Search bars on Findings, Secrets, URLs, Endpoints, and JS tabs
- Instant filtering as you type
- Case-insensitive matching

---

## ğŸ¯ Roadmap

### Planned Features
- [ ] Export reports in PDF/HTML
- [ ] Scheduled/automated scans
- [ ] Multi-user support with authentication
- [ ] Scan history and comparison
- [ ] Custom LLM prompts
- [ ] Plugin system for additional tools
- [ ] REST API for programmatic access
- [ ] Docker containerization
- [ ] Kubernetes deployment configs

### UI Enhancements
- [ ] Sound effects (terminal beeps)
- [ ] Completion animations
- [ ] Keyboard shortcuts
- [ ] Dark/stealth mode toggle
- [ ] Customizable color themes

---

## ğŸ“š Technical Details

### Pydantic Models
All data models use `ConfigDict` for proper serialization:
```python
class Endpoint(BaseModel):
    model_config = ConfigDict(json_encoders={datetime: lambda v: v.isoformat()})
    
    url: str
    method: str = "GET"
    timestamp: datetime = Field(default_factory=datetime.now)
```

### Async Scanning
Reconnaissance tools run asynchronously:
```python
async def run_scan_async(scan_id, target, request):
    # Parallel execution
    subdomains = await asyncio.to_thread(run_subfinder, domain)
    urls_wayback = await asyncio.to_thread(run_waybackurls, domain)
    # ... more tools
```

### WebSocket Protocol
```javascript
ws = new WebSocket(`ws://localhost:8000/ws/scan/${scan_id}`);

ws.onmessage = (event) => {
    const data = JSON.parse(event.data);
    // { progress: 75, message: "Analyzing JS...", status: "running" }
};
```

---

## ğŸ¤ Contributing

Contributions are welcome! Areas for improvement:
- Additional reconnaissance tools integration
- New LLM prompts for specialized analysis
- UI/UX enhancements
- Performance optimizations
- Bug fixes and error handling

---

## âš ï¸ Disclaimer

This tool is for **authorized security testing only**. Always obtain proper permission before scanning any targets. The developers are not responsible for misuse or damage caused by this tool.

---

## ğŸ“„ License

MIT License - See LICENSE file for details

---

## ğŸ™ Credits

**Built with:**
- FastAPI - Modern web framework
- Ollama - Local LLM inference
- Subfinder, Httpx, Katana - Reconnaissance tools
- Tailwind CSS - Utility-first styling
- Lead Author & Maintainer: **Cycus Pectus**

**Inspired by:**
- Matrix digital rain aesthetic
- Traditional security tools (nmap, metasploit)
- Modern AI-powered security platforms

---

## ğŸ“ Support

For issues, questions, or feature requests:
- Check the output logs in the terminal
- Verify Ollama is running: `ollama serve`
- Ensure all dependencies are installed
- Review this README for troubleshooting

---

**Happy Hacking! ğŸ¦…ğŸ’š**

Made with ğŸ’š by security researchers, for security researchers.
